{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKc8K9_57UEz"
      },
      "source": [
        "# CS171-EE142 - Fall 2022 - Homework 3\n",
        "\n",
        "# Due: Tuesday, November 15, 2022 @ 11:59pm\n",
        "\n",
        "### Maximum points: 80 pts\n",
        "\n",
        "\n",
        "## Submit your solution to Gradescope:\n",
        "1. Submit a single PDF to **HW3**\n",
        "2. Submit your jupyter notebook to **HW3-code**\n",
        "\n",
        "**See the additional submission instructions at the end of this notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL5tIX4c9z6s"
      },
      "source": [
        "\n",
        "## Enter your information below:\n",
        "\n",
        "### Your Name (submitter): Iraj Shrotri\n",
        "\n",
        "### Your student ID (submitter): 862077452\n",
        "    \n",
        "    \n",
        "<b>By submitting this notebook, I assert that the work below is my own work, completed for this course.  Except where explicitly cited, none of the portions of this notebook are duplicated from anyone else's work or my own previous work.</b>\n",
        "\n",
        "\n",
        "## Academic Integrity\n",
        "Each assignment should be done  individually. You may discuss general approaches with other students in the class, and ask questions to the TAs, but  you must only submit work that is yours . If you receive help by any external sources (other than the TA and the instructor), you must properly credit those sources, and if the help is significant, the appropriate grade reduction will be applied. If you fail to do so, the instructor and the TAs are obligated to take the appropriate actions outlined at http://conduct.ucr.edu/policies/academicintegrity.html . Please read carefully the UCR academic integrity policies included in the link.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsywQWEI8pzj"
      },
      "source": [
        "# Overview \n",
        "In this assignment you will implement a two-layer neural network. You will implement the loss functions, gradients, optimizers to train the network and test its performance on MNIST dataset. \n",
        "\n",
        "For this assignment we will use the functionality of Pandas (https://pandas.pydata.org/), Matplotlib (https://matplotlib.org/), and Numpy (http://www.numpy.org/). \n",
        "\n",
        "If you are asked to **implement** a particular functionality, you should **not** use an existing implementation from the libraries above (or some other library that you may find). When in doubt, please ask. \n",
        "\n",
        "Before you start, make sure you have installed all those packages in your local Jupyter instance\n",
        "\n",
        "## Read *all* cells carefully and answer all parts (both text and missing code)\n",
        "\n",
        "You will complete all the code marked `TODO` and answer descriptive/derivation questions \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d6urIY6Ci2D"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# make sure you import here everything else you may need"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vBsJizSAN5C"
      },
      "source": [
        "### Load MNIST Dataset \n",
        "\n",
        "For this assignment, we will use [MNIST](https://en.wikipedia.org/wiki/MNIST_database) handwritten digits data set. The dataset consists 10 handwritten digits (0,1,...,9). It is a widely used dataset to demonstrate simple image classification problem.\n",
        "\n",
        "MNIST dataset is publicly available from different sources. We will be using MNIST from Keras package. If you do not have Keras installed, you can find the installation guide [here](https://www.tutorialspoint.com/keras/keras_installation.htm). \n",
        "\n",
        "In short, you need to run ```conda install -c anaconda keras``` or ```pip install keras```\n",
        "\n",
        "The training data consists of 60000 images of size $28 \\times 28$ pixels; the test data consists of 10000 images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdo3YbSzAN5D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "ec812b01-d171-40c1-ce14-908714c46087"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "print('Training data shape:',x_train.shape)\n",
        "print('Test data shape:',x_test.shape)\n",
        "\n",
        "n_img=10\n",
        "plt.figure(figsize=(n_img*2,2))\n",
        "plt.gray()\n",
        "for i in range(n_img):\n",
        "    plt.subplot(1,n_img,i+1)\n",
        "    plt.imshow(x_train[i])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Training data shape: (60000, 28, 28)\n",
            "Test data shape: (10000, 28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x144 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw4N4norAN5D"
      },
      "source": [
        "We will be vectorizing the training and test images. So, the size of each vector will be 784."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOIMLKYtAN5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acc92203-4354-41d5-cf09-d2069b8cf099"
      },
      "source": [
        "x_train=x_train.reshape(x_train.shape[0],-1)\n",
        "x_test=x_test.reshape(x_test.shape[0],-1)\n",
        "\n",
        "print('Training data shape after reshaping:',x_train.shape)\n",
        "print('Test data shape after reshaping::',x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape after reshaping: (60000, 784)\n",
            "Test data shape after reshaping:: (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHVQmrbIAN4-"
      },
      "source": [
        "## Question 1: Binary classification using neural network [45 pts]\n",
        "\n",
        "We will start with classification of images for two different digits using a two-layer network with a cross entropy loss. \n",
        "\n",
        "In the next question, we will extend the same architecture to multi-class classification. \n",
        "\n",
        "Pick any two digits out of ten for our classification (say 5 and 8), which we will assign label \"0\" or \"1\". \n",
        "\n",
        "Pick same number of images from each class for training and create arrays for input and output (say 1000). \n",
        "\n",
        "```\n",
        "# train_x -- N x 784 array of training input\n",
        "# train_y -- N x 1 array of binary labels \n",
        "```  \n",
        "\n",
        "If you use 1000 images from each class N = 2000. You can increase the number of training samples if you like. It is just a suggestion. \n",
        "\n",
        "\n",
        "We also need to transpose the dimension of the data so that their size becomes $784\\times N$. It will be helpful to feed it to our model based on our notations.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fir2-wZWAN5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c82bb55-5e11-411f-b457-a4b4c26a4449"
      },
      "source": [
        "def extract_binary_classification_dataset(x, y, label1, label2, num_samples):\n",
        "    \"\"\"Make a subset dataset from MNIST, containing only 2 classes for binary classification task \n",
        "    Args:\n",
        "        x (numpy.ndarray): data, can be x_train or x_test\n",
        "        y (numpy.ndarray): labels of data, can be y_train or y_test\n",
        "        label1 (int): the first class you pick, e.g. 5\n",
        "        label2 (int): the second class you pick, e.g. 8\n",
        "        num_samples (int): the number of images you select for each class, e.g. 1000\n",
        "    Returns:\n",
        "        x_ (numpy.ndarray): the data for 2 picked classes\n",
        "        y_ (numpy.ndarray): the corresponding labels for 2 picked classes\n",
        "    \"\"\"\n",
        "    # for class 1\n",
        "    x1 = x[y == label1]\n",
        "    x1 = x1[:num_samples]\n",
        "    y1 = np.zeros(len(x1))\n",
        "\n",
        "    # for class 2\n",
        "    x2 = x[y == label2]\n",
        "    x2 = x2[:num_samples]\n",
        "    y2 = np.ones(len(x2))\n",
        "\n",
        "    # combine 2 classes\n",
        "    x_ = np.concatenate((x1,x2),axis=0)\n",
        "    y_ = np.concatenate((y1,y2),axis=0)\n",
        "    return x_, y_\n",
        "\n",
        "\n",
        "# Pick your own digits\n",
        "label1 = 7\n",
        "label2 = 1\n",
        "num_samples = 1000\n",
        "\n",
        "# Train & test data\n",
        "train_x, train_y = extract_binary_classification_dataset(x_train, y_train, label1, label2, num_samples)\n",
        "test_x, test_y = extract_binary_classification_dataset(x_test, y_test, label1, label2, num_samples)\n",
        "\n",
        "# reshape data \n",
        "train_x = train_x.T\n",
        "test_x = test_x.T\n",
        "print(\"Training data shape:\", train_x.shape)\n",
        "print(\"Test data shape:\", test_x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (784, 2000)\n",
            "Test data shape: (784, 2000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdeO0YieAN5E"
      },
      "source": [
        "### Network Architecture\n",
        "\n",
        "We will be using a two layer neural network in our experiment. The input layer will have 784 nodes, the hidden layer will have 256 nodes and the output layer will have 1 node. Each node will have $\\textit{sigmoid}$ activation function.\n",
        "\n",
        "The equations for feedforward operation will be the following:\n",
        "\n",
        "$$\\mathbf{z}^{(1)}=W^{(1)} \\mathbf{x}+ \\mathbf{b}^{(1)}\\\\\\mathbf{y}^{(1)}=\\varphi(\\mathbf{z}^{(1)})\\\\\\mathbf{z}^{(2)}=W^{(2)}  \\mathbf{y}^{(1)}+ \\mathbf{b}^{(2)} \\\\\\mathbf{y}^{(2)}=\\varphi(\\mathbf{z}^{(2)})$$\n",
        "\n",
        "where $\\mathbf{x}\\in \\mathbb{R}^{784}$ is the input layer, $\\mathbf{y}^{(1)}\\in \\mathbb{R}^{256}$ is the hidden layer, $\\mathbf{y}^{(2)} \\in \\mathbb{R}$ is the output layer, $W^{(1)}\\in \\mathbb{R}^{256\\times 784}$ is the first layer weights, $W^{(2)}\\in \\mathbb{R}^{1\\times 256}$ is the second layer weights, $\\mathbf{b}^{(1)}\\in \\mathbb{R}^{256}$ is the first layer bias, $\\mathbf{b}^{(2)}\\in \\mathbb{R}$ is the second layer bias, $\\varphi(\\cdot)$ is the activation function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWw3zn2_AN5F"
      },
      "source": [
        "### Network initialization [5 pts]\n",
        "\n",
        "We initialize the weights for $W^{(1)}$ and $W^{(2)}$ with random values drawn from normal distribution with zero mean and 0.01 standard deviation. We will initialize bias vectors $\\mathbf{b}^{(1)}$ and $\\mathbf{b^{(2)}}$ with zero values. \n",
        "\n",
        "We can fix the seed for random initialization for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k52OUaoAN5F"
      },
      "source": [
        "def TwoLayerNetwork(layer_dims=[784,256,1]):\n",
        "    # Fix the seed\n",
        "    np.random.seed(5)\n",
        "    w1 = np.random.normal(loc=0, scale=0.01, size=(256,784))\n",
        "    w2 = np.random.normal(loc=0, scale=0.01, size=(1,256))\n",
        "    b1 = np.zeros((256,1))\n",
        "    b2 = np.zeros((1,1))\n",
        "    params = [w1, w2, b1, b2]\n",
        "    return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xLDm_wkAN5F"
      },
      "source": [
        "### Sigmoid activation function \n",
        "Now we will write the sigmoid activation function as \n",
        "\n",
        "$$ \\varphi(z) = \\frac{1}{1+e^{-z}}$$\n",
        "\n",
        "Note that derivative of __sigmoid__ is $\\varphi'(z) = \\varphi(z) (1-\\varphi(z))$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CPxvM0UAN5F"
      },
      "source": [
        "def sigmoid(Z):\n",
        "    Y = 1/(1+np.exp(-Z))\n",
        "    return Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGuGMhzeAN5G"
      },
      "source": [
        "### Cross entropy loss function [5 pts]\n",
        "We will minimize the binary cross entropy loss function. You will use the true labels and predicted labels of a batch of N samples. \n",
        "\n",
        "Binary crossentropy loss for $i^{th}$ sample can be written as \n",
        "\n",
        "$$Loss_i = -y_i \\log y^{(2)}_i- (1-y_i) \\log (1-y^{(2)}_i)$$\n",
        "\n",
        "where $y_i$ is the true label. We can find the average loss for a batch of N samples as $Loss=\\frac{1}{N}\\sum_{i=1}^{N} Loss_i$.\n",
        "\n",
        "Note that the gradient of the cross entropy loss w.r.t. the output is \n",
        "\n",
        "$$ \\nabla_{y^{(2)}} Loss_i = -\\frac{y_i}{y_i^{(2)}} + \\frac{1-y_i}{1-y_i^{(2)}} = \\frac{y_i^{(2)}-y_i}{y_i^{(2)}(1-y_i^{(2)})}.$$\n",
        "\n",
        "We can also show that $$\\delta^{(2)} = \\nabla_{\\mathbf{z}^{(2)}} Loss_i  = \\nabla_{y^{(2)}} Loss_i \\odot \\varphi'(\\mathbf{z})= y_i^{(2)}-y_i,$$ \n",
        "where $\\odot$ denotes element-wise multiplication of the arrays. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7KkfTXeAN5G"
      },
      "source": [
        "def CrossEntropyLoss(Y_true, Y2):\n",
        "    # TODO \n",
        "    Loss = -Y_true*np.log(Y2) - (1-Y_true)*np.log(1-Y2)\n",
        "    return Loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnFFFVP1AN5F"
      },
      "source": [
        "### Forward propagation  [5 pts]\n",
        "Next, we will write the code for the forward pass for two layer network. Each layer consists of an affine function (fully-connected layer) followed by an activation function. You wil also return the intermediate results ($\\mathbf{x}, \\mathbf{z}^{(1)}, \\mathbf{y}^{(1)}, \\mathbf{z}^{(2)}$) in addition to final output ($\\mathbf{y}^{(2)}$). You will need the intermediate outputs for the backpropagation step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBHoC1_TAN5F"
      },
      "source": [
        "def forward(X, params):\n",
        "    # TODO \n",
        "    # Write your codes here\n",
        "    # X -- 784 x N array \n",
        "    # params -- \n",
        "      # W1 -- 256 x 784 matrix\n",
        "      # b1 -- 256 x 1 vector\n",
        "      # W2 -- 1 x 256 matrix\n",
        "      # b2 -- 1 x 1 scalar \n",
        "    # Y2 -- 1 x N output\n",
        "        # intermediate -- X, Z1, Y1, Z2 \n",
        "      # Z1 -- 256 x N matrix\n",
        "      # Y1 -- 256 x N matrix\n",
        "      # Z2 -- 1 x N array\n",
        "    Z1 = np.dot(params[0], X) + params[2]\n",
        "    Y1 = sigmoid(Z1)\n",
        "    Z2 = np.dot(params[1], Y1) + params[3]\n",
        "    Y2 = sigmoid(Z2)\n",
        "    intermediate = [X, Z1, Y1, Z2]\n",
        "    return Y2, intermediate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4ZM2NLAAN5G"
      },
      "source": [
        "### Backpropagration step [10 pts]\n",
        "Now we will implement the backpropagation step for the two layer neural network. \n",
        "\n",
        "You will need the gradient of the Loss w.r.t. $W^{(l)},\\mathbf{b}^{(l)}$ for $l = 1,2$ for all the training samples.  \n",
        "\n",
        "\n",
        "\n",
        "We saw that we can write the gradient of Loss with respect to $W^{(l)}, \\mathbf{b}^{(l)}$ for a single sample as\n",
        "\n",
        "$$\\nabla_{W^{(l)}} Loss_i = \\delta^{(l)} \\mathbf{y}^{(l-1)T},$$  \n",
        "$$\\nabla_{\\mathbf{b}^{(l)}} Loss_i = \\delta^{(l)},$$\n",
        "\n",
        "where \n",
        "$$\\delta^{(l)} = \\nabla_{\\mathbf{z}^{(l)}} Loss_i = \\nabla_{\\mathbf{y}^{(l)}} Loss_i \\odot \\varphi'(\\mathbf{z}^{(l)}).$$ \n",
        "\n",
        "\n",
        "For the the last layer, we can compute $\\delta^{(L)}$ by plugging the value of $\\nabla_{\\mathbf{y}^{(L)}} Loss$ as described above. \n",
        "\n",
        "For the intermediate layers $l<L$, we can write \n",
        "$$\\delta^{(l)} = W^{(l+1)T}\\delta^{(l+1)} \\odot \\varphi'(\\mathbf{z}^{(l)}).$$ \n",
        "\n",
        "\n",
        "\n",
        "**Once we have the gradients $\\nabla_{W^{(l)}} Loss_i, \\nabla_{\\mathbf{b}^{(l)}} Loss_i$ for all $i$. We can compute their average to compute the gradient of the total loss function $\\frac{1}{N} \\sum_{i=1}^N Loss_i$ as**\n",
        "\n",
        "$$\\nabla_{W^{(l)}} Loss = \\frac{1}{N} \\sum_i \\nabla_{W^{(l)}} Loss_i, $$\n",
        "$$ \\nabla_{\\mathbf{b}^{(l)}} Loss = \\frac{1}{N} \\sum_i  \\nabla_{\\mathbf{b}^{(l)}} Loss_i.$$\n",
        "\n",
        "**Please refer to the slides and lectures for more details.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODa4OXAqAN5G"
      },
      "source": [
        "def backward(Y_true, Y2, intermediate, params):\n",
        "    \n",
        "    # Inputs: \n",
        "      # Y_true -- 1 x N true labels\n",
        "      # Y2 -- 1 x N output of the last layer\n",
        "      # intermediate -- X, Z1, Y1, Z2 \n",
        "      # params -- W1, b1, W2, b2 \n",
        "    \n",
        "    # Outputs: \n",
        "      # grads -- [grad_W1, grad_b1, grad_W2, grad_b2]\n",
        "    \n",
        "    # TODO \n",
        "    X = intermediate[0]\n",
        "    x_transpose = np.transpose(X)\n",
        "    sig_2 = Y2-Y_true\n",
        "    sig_1 = np.dot(params[1].T, sig_2)*sigmoid(intermediate[1])*(1-sigmoid(intermediate[1]))\n",
        "\n",
        "    grad_w1 = np.dot(sig_1, x_transpose)\n",
        "    grad_b1 = sig_1\n",
        "    y1_transpose = np.transpose(intermediate[2])\n",
        "    \n",
        "    grad_w2 = np.dot(sig_2, y1_transpose)\n",
        "    grad_b2 = sig_2\n",
        "    grads = [grad_w1, grad_b1, grad_w2, grad_b2] \n",
        "          \n",
        "    return grads"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlHu8oIaAN5G"
      },
      "source": [
        "### Optimizer [5 pts]\n",
        "We will use a standard gradient descent-based optimizer to minimize the loss function. You have already implemented gradient descent in HW2. You may have to adjust learning rate that provides you best training/validation performance. In this exercise, we are not using validation data; in practice, you should use it to tune your hyperparameters such as learning rate, network architecture etc.\n",
        "\n",
        "You can use same learning rate for all weights in this assignment. \n",
        "\n",
        "You should update $W^1, \\mathbf{b}^1, W^2, \\mathbf{b}^2$ as \n",
        "$$ W^1 \\gets W^1 - \\alpha \\nabla_{W^1} Loss $$\n",
        "$$ \\mathbf{b}^1 \\gets \\mathbf{b}^1 - \\alpha \\nabla_{\\mathbf{b}^1} Loss $$ \n",
        "$$ W^2 \\gets W^2 - \\alpha \\nabla_{W^2} Loss $$ \n",
        "$$ \\mathbf{b}^2 \\gets \\mathbf{b}^2 - \\alpha \\nabla_{\\mathbf{b}^2} Loss $$ \n",
        "$\\alpha$ is the learning rate. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noqJ8U_PAN5G"
      },
      "source": [
        "def GD(params, grads, learning_rate):\n",
        "    \n",
        "    # updated params = old params - learning rate * gradient of Loss computed at old params\n",
        "    # TODO \n",
        "    params[0] = params[0] - learning_rate*grads[0]\n",
        "    params[2] = params[2] - learning_rate*grads[1]\n",
        "    params[1] = params[1] - learning_rate*grads[2]\n",
        "    params[3] = params[3] - learning_rate*grads[3]\n",
        "        \n",
        "    return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adhSifEGAN5G"
      },
      "source": [
        "### Train the Model [5 pts]\n",
        "We will train the model using the functions we wrote above. \n",
        "\n",
        "First, we specify the number of nodes in the layers, number of epochs and learning rate. Then we initialize the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKwAatEkAN5H"
      },
      "source": [
        "layer_dims = [train_x.shape[0],256,1]\n",
        "epochs = 100\n",
        "lr = 0.00001\n",
        "\n",
        "params = TwoLayerNetwork(layer_dims)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdi_L3xYAN5H"
      },
      "source": [
        "Then we train the network for the number of epochs specified above. In every epoch, we will do the following:\n",
        "1. Calculate the forward pass to get estimated labels.\n",
        "2. Use the estimated labels calculate loss. We will be recording loss for every epoch.\n",
        "3. Use backpropagation to calculate gradients.\n",
        "4. Use gradient descent to update the weights and biases.\n",
        "\n",
        "You should store the loss value after every epoch in an array ```loss_history```  and print the loss value after every few epochs (say 20). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtEPxEleAN5H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dafea0cd-a259-4990-bcb0-d4d119b0a880"
      },
      "source": [
        "# TODO \n",
        "params = TwoLayerNetwork(layer_dims)\n",
        "loss_history = []\n",
        "for i in range(epochs):\n",
        "  Y2, intermediate = forward(train_x, params) \n",
        "  Loss = CrossEntropyLoss(train_y, Y2) \n",
        "  Loss = sum(Loss[0])/2000\n",
        "  loss_history.append(Loss)\n",
        "  grads = backward(train_y, Y2, intermediate, params)\n",
        "  params = GD(params, grads, lr)\n",
        "  if i%20 == 0:\n",
        "    print(f\"Each {i} epochs's loss: \", Loss)\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Each 0 epochs's loss:  0.677762653608669\n",
            "Each 20 epochs's loss:  0.13739296199940043\n",
            "Each 40 epochs's loss:  0.06772277137375574\n",
            "Each 60 epochs's loss:  0.04606948979840566\n",
            "Each 80 epochs's loss:  0.035435786561474954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-7VVZ6iAN5H"
      },
      "source": [
        "Now we will plot the recorded loss values vs epochs. We will observe the training loss decreasing with the epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu8zTsABAN5H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "9707d7f5-e1c5-469a-d5bd-58b3c4c29f93"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(loss_history)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZlLv1NbAN5H"
      },
      "source": [
        "### Evaluation on test data [5 pts]\n",
        "\n",
        "Now we will be evaluating the accuracy we get from the trained model. We feed training data and test data to the forward model along with the trained parameters. \n",
        "\n",
        "Note that, we need to covert the output probability of the forward pass to binary labels before evaluating accuracy. Since the model provides the posterior probability $p(y = 1 | x)$ in range [0,1]. We can binarize them using 0.5 as a theshold (i.e. if $y_i^{(2)}\\geq 0.5$, $y_i^{(2)} \\gets 1$ otherwise  $y_i^{(2)} \\gets 0$)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKZ7BSZjAN5I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b629c9-47a3-459a-c6a6-5b5f5fdf5138"
      },
      "source": [
        "# TODO \n",
        "Y_thesh = []\n",
        "for x in Y2[0]:\n",
        "  if x >= 0.5:\n",
        "    Y_thesh.append(1)\n",
        "  else:\n",
        "    Y_thesh.append(0)\n",
        "\n",
        "print(\"Training accuracy:\",np.mean(Y_thesh==train_y))\n",
        "\n",
        "\n",
        "\n",
        "Y2_test, intermediate = forward(test_x, params)\n",
        "Y_test_thesh = []\n",
        "for i in Y2_test[0]:\n",
        "  if i >= 0.5:\n",
        "    Y_test_thesh.append(1)\n",
        "  else:\n",
        "    Y_test_thesh.append(0)\n",
        "\n",
        "\n",
        "print(\"Test accuracy:\",np.mean(Y_test_thesh==test_y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.9945\n",
            "Test accuracy: 0.988\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba-laCd-4OkR"
      },
      "source": [
        "### Visualize some of the correct/miscalassified images [5 pts]\n",
        "\n",
        "Now we will look at some images from training and test sets that were misclassified. \n",
        "\n",
        "Training set. \n",
        "Pick 5 images from each class that are correcly and incorreclty classified. \n",
        "True/False Positive/Negatives\n",
        "\n",
        "Test set. \n",
        "Pick 5 images from each class that are correcly and incorreclty classified. \n",
        "True/False Positive/Negatives\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O5zZTCn4N18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "38e61132-5cdf-434a-b054-af4914c5f8fb"
      },
      "source": [
        "import random\n",
        "# TODO \n",
        "# Training set\n",
        "print(\"Training set examples for true/false positive/negative\")\n",
        "Y_hat, caches = forward(train_x, params)\n",
        "\n",
        "Y_hat_thesh = []\n",
        "for i in Y_hat[0]:\n",
        "  if i >= 0.5:\n",
        "    Y_hat_thesh.append(1)\n",
        "  else:\n",
        "    Y_hat_thesh.append(0)\n",
        "\n",
        "\n",
        "corr_list = []\n",
        "incorr_list = []\n",
        "count = 0\n",
        "for i in Y_thesh==train_y:\n",
        "  count += 1\n",
        "  if i == 1:\n",
        "    corr_list.append(count)\n",
        "  else:\n",
        "    incorr_list.append(count)\n",
        "\n",
        "n_img=5\n",
        "train_x_fig = train_x.T\n",
        "train_x_fig = train_x_fig.reshape(2000,28,28)\n",
        "\n",
        "# correct images\n",
        "print(\"Correct images\")\n",
        "plt.figure(figsize=(n_img*2,2))\n",
        "plt.gray()\n",
        "for i in range(n_img):\n",
        "  x = random.randrange(i,len(corr_list))\n",
        "  plt.subplot(1,n_img,i+1)\n",
        "  plt.imshow(train_x_fig[corr_list[x]])\n",
        "plt.show()\n",
        "\n",
        "# incorrect images\n",
        "print(\"Incorrect images\")\n",
        "plt.figure(figsize=(n_img*2,2))\n",
        "plt.gray()\n",
        "for i in range(n_img):\n",
        "  x = random.randrange(i,len(incorr_list))\n",
        "  plt.subplot(1,n_img,i+1)\n",
        "  plt.imshow(train_x_fig[incorr_list[x]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set examples for true/false positive/negative\n",
            "Correct images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x144 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incorrect images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x144 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jym9VlP-_0rd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "a635dc74-afd2-4607-8b28-f90a921a0b05"
      },
      "source": [
        "# Test set\n",
        "print(\"Test set examples for true/false positive/negative\")\n",
        "Y_hat, caches = forward(test_x, params)\n",
        "\n",
        "Y_hat_thesh = []\n",
        "for i in Y_hat[0]:\n",
        "  if i >= 0.5:\n",
        "    Y_hat_thesh.append(1)\n",
        "  else:\n",
        "    Y_hat_thesh.append(0)\n",
        "\n",
        "\n",
        "corr_list = []\n",
        "incorr_list = []\n",
        "count = 0\n",
        "for i in Y_hat_thesh==test_y:\n",
        "  count += 1\n",
        "  if i == 1:\n",
        "    corr_list.append(count)\n",
        "  else:\n",
        "    incorr_list.append(count)\n",
        "\n",
        "n_img=5\n",
        "\n",
        "test_x_fig = test_x.T\n",
        "test_x_fig = test_x_fig.reshape(2000,28,28)\n",
        "\n",
        "# correct images\n",
        "print(\"Correct images\")\n",
        "plt.figure(figsize=(n_img*2,2))\n",
        "plt.gray()\n",
        "for i in range(n_img):\n",
        "  x = random.randrange(i,len(corr_list))\n",
        "  plt.subplot(1,n_img,i+1)\n",
        "  plt.imshow(test_x_fig[corr_list[x]])\n",
        "plt.show()\n",
        "\n",
        "# incorrect images\n",
        "print(\"Incorrect images\")\n",
        "plt.figure(figsize=(n_img*2,2))\n",
        "plt.gray()\n",
        "for i in range(n_img):\n",
        "  x = random.randrange(i,len(incorr_list))\n",
        "  plt.subplot(1,n_img,i+1)\n",
        "  plt.imshow(test_x_fig[incorr_list[x]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set examples for true/false positive/negative\n",
            "Correct images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x144 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incorrect images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x144 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBEj5ST72SG6"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoli2hpzp2gy"
      },
      "source": [
        "## Question 2. Multiclass classification [35 pts] \n",
        "\n",
        "Now we will build a classifier to separate all the digits. For this purpose, we will only change the last layer and the loss. \n",
        "\n",
        "\n",
        "Instead of using a single output, we will provide 10 outputs; and instead of using a binary cross entropy loss, we will use mutli-class cross entropy loss. \n",
        "\n",
        "In multinomal logistic regression (aka softmax regression), we define the posterior probability of label $y \\in \\{0,\\ldots, K-1\\}$ as \n",
        "\n",
        "\n",
        "$$p(y = c | \\mathbf{x}) = \\frac{\\exp(\\mathbf{w}_c^T\\mathbf{x})}{\\sum_{k=1}^K \\exp(\\mathbf{w}_k^T\\mathbf{x})} = \\mathbf{p}_c.$$ \n",
        "\n",
        "In other words, last layer of the network provides a probability vector $\\mathbf{p} \\in \\mathbb{R}^K$, such that each $0 \\le \\mathbf{p}_c \\le 1$ and $\\sum_c \\mathbf{p}_c = 1$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxGPKVAUBO-w"
      },
      "source": [
        "### Softmax function [5 pts]\n",
        "\n",
        "Let us first define the softmax function, which is a multinomal extension of the sigmoid function that maps a vector of length $K$ to a probability vector. \n",
        "\n",
        "We can define ```softmax``` function on a vector $\\mathbf{z} \\in \\mathbb{R}^K$ as $\\mathbf{p} = \\text{softmax}(\\mathbf{z})$: \n",
        "\n",
        "$$\\mathbf{p}_c(\\mathbf{z}) = \\frac{\\exp(\\mathbf{z}_c)}{\\sum_{k=1}^K \\exp(\\mathbf{z}_k)}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wezeelLcBSCo"
      },
      "source": [
        "def softmax(Z):\n",
        "    # Z -- K x N numpy.ndarray, K is the number of classes, N is the number of samples\n",
        "    # TODO  \n",
        "    probs = np.exp(Z)\n",
        "    probs /= np.sum(probs,axis=0,keepdims=True)\n",
        "    return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J53N9_wWMUf"
      },
      "source": [
        "We have to note that the numerical range of floating point numbers in numpy is limited. For `float64` the upper bound is $10^{308}$. For exponential, its not difficult to overshoot that limit, in which case python returns `nan`.\n",
        "\n",
        "To make our softmax function numerically stable, we simply normalize the values in the vector, by multiplying the numerator and denominator with a constant `C` as\n",
        "\n",
        "\\begin{align*}\n",
        "\\mathbf{p}_c  &= \\frac{\\exp(\\mathbf{z}_c)}{\\sum_{k=1}^K \\exp(\\mathbf{z}_k)} \\\\\n",
        "& = \\frac{C\\exp(\\mathbf{z}_c)}{C\\sum_{k=1}^K \\exp(\\mathbf{z}_k)}\\\\\n",
        "& = \\frac{\\exp(\\mathbf{z}_c + \\log C)}{C\\sum_{k=1}^K \\exp(\\mathbf{z}_k + \\log C)}.\n",
        "\\end{align*}\n",
        "\n",
        "We can choose an arbitrary value for `log(C)` term, but generally `log(C) = −max(z)` is chosen\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzmyZdoqXO_v"
      },
      "source": [
        "def stable_softmax(Z): \n",
        "    # Z -- K x N numpy.ndarray, K is the number of classes, N is the number of samples\n",
        "    # TODO (this is optional)\n",
        "    \n",
        "    probs = np.exp(Z-max(Z))/(pow(10,-max(Z))*sum(np.exp(Z-max(Z)))) \n",
        "    return probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSGHPdySbpbj"
      },
      "source": [
        "### Derivative of the softmax function\n",
        "\n",
        "We can show that the derivative of the __softmax__ function with respect to any input can be written as \n",
        "\n",
        "$$ \\frac{\\partial \\mathbf{p}_i}{\\partial \\mathbf{z}_j} = \\begin{cases} \\mathbf{p}_i(1-\\mathbf{p}_j) & i = j \\\\ \\mathbf{p}_i (-\\mathbf{p}_j) & i \\ne j. \\end{cases}$$\n",
        "\n",
        "[More info here](https://deepnotes.io/softmax-crossentropy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0qcy_JAArEo"
      },
      "source": [
        "### Multiclass cross entropy loss function [5 pts]\n",
        "\n",
        "We will minimize the cross entropy loss. You will use the true labels and predicted labels of a batch of N samples. \n",
        "\n",
        "The multi-class cross entropy loss for $i^{th}$ sample can be written as \n",
        "$$Loss_i = -\\sum_c \\mathbf{1}(y_i = c) \\log \\mathbf{p}_c $$\n",
        "where $y_i$ is the true label and \n",
        "\n",
        "$$\\mathbf{1}(y_i = c) = \\begin{cases} 1 & y_i =c \\\\ 0 & \\text{otherwise} \\end{cases}$$ \n",
        "is an indicator function. \n",
        "\n",
        "We can find the average loss for a batch of N samples as $Loss=\\frac{1}{N}\\sum_{i=1}^{N} Loss_i$. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tebVzE2SAoTB"
      },
      "source": [
        "def MultiClassCrossEntropyLoss(Y_true, probs):\n",
        "  \n",
        "  # TODO \n",
        "  # Write your code here\n",
        "\n",
        "  # probs -- K x N array\n",
        "  # Y_true -- 1 x N array \n",
        "  # loss --  sum Loss_i over N samples \n",
        "  Loss = np.zeros([1, len(Y_true)])\n",
        "  for i in range(len(Y_true)):\n",
        "    P_ = probs[int(Y_true[i]), i]\n",
        "    Loss[0,i] = -np.log(P_+1e-7)\n",
        "  Loss = np.mean(Loss)\n",
        "  return Loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbRPrVLpjFIo"
      },
      "source": [
        "### Derivative of the cross entropy loss \n",
        "\n",
        "Let us assume that $\\mathbf{p} = \\text{softmax}(\\mathbf{z})$. \n",
        "\n",
        "Note that the derivative of the loss w.r.t. $\\mathbf{p}_j$ can be written as \n",
        "$$\\frac{\\partial Loss_i }{\\partial \\mathbf{p}_j} = \\begin{cases} -1/\\mathbf{p}_j & j = y_i \\\\ 0 & j \\ne y_i \\end{cases}. $$\n",
        "\n",
        "Note that we can use _total derivative_ to compute the derivative of the loss for $i$th sample w.r.t. $j$th entry in $\\mathbf{z}$ as\n",
        "\n",
        "\\begin{align*}\n",
        "\\frac{\\partial Loss_i}{\\partial \\mathbf{z}_j} = \\sum_c \\frac{\\partial Loss_i}{\\partial \\mathbf{p}_c}\\frac{\\partial \\mathbf{p}_c}{\\partial \\mathbf{z}_j}.\n",
        "\\end{align*}\n",
        "\n",
        "From our discussion above, we know that the $\\frac{\\partial Loss_i}{\\partial \\mathbf{p}_c} = 0$ if $c \\ne y_i$. \n",
        "\n",
        "\n",
        "\\begin{align*}\n",
        "\\frac{\\partial Loss_i}{\\partial \\mathbf{z}_j} &= -\\frac{1}{\\mathbf{p}_c} \\frac{\\partial \\mathbf{p}_c}{\\partial \\mathbf{z}_j} \\\\\n",
        "& = \\begin{cases} \\mathbf{p}_j - 1 & j = y_i \\\\ \\mathbf{p}_j & j \\ne y_i. \\end{cases}\n",
        "\\end{align*}\n",
        "\n",
        "Therefore, $$\\delta^{(2)} = \\nabla_{\\mathbf{z}^{(2)}} Loss_i = \\mathbf{p} - \\mathbf{1}_{y_i}.$$\n",
        "\n",
        "where $\\mathbf{1}_{y_i}$ is a __one-hot vector__ that has length $K$ and is zero everywhere except 1 at index same as $y_i$. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "462ORdiFLdz2"
      },
      "source": [
        "### Training data\n",
        "\n",
        "Let us pick training data for multi-class classification. \n",
        "\n",
        "Pick same number of images from each class for training and create arrays for input and output. \n",
        "\n",
        "```\n",
        "# train_x -- N x 784 array of training input\n",
        "# train_y -- N x 1 array of labels \n",
        "```  \n",
        "\n",
        "If you use 1000 images from each class N = 10000. You can increase the number of training samples if you like. You may also use unequal number of images in each class. \n",
        "\n",
        "We also need to transpose the dimension of the data so that their size becomes $784\\times N$. It will be helpful to feed it to our model based on our notations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZ6Z-yPgL3xm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34843f93-d25d-4831-e25a-9ec7ef118482"
      },
      "source": [
        "# Pick training samples \n",
        "num_samples = 1000\n",
        "\n",
        "# Training data\n",
        "x = np.zeros((0,784))\n",
        "y = np.zeros((0))\n",
        "for label in range(10):\n",
        "  x1 = x_train[y_train == label]  \n",
        "  x1 = x1[:num_samples]\n",
        "  y1 = y_train[y_train == label]\n",
        "  y1 = y1[:num_samples]\n",
        "  \n",
        "  x = np.concatenate((x,x1),axis=0)\n",
        "  y = np.concatenate((y,y1),axis=0)\n",
        "\n",
        "train_x = x\n",
        "train_y = y\n",
        "print(\"Training data shape:\", train_x.shape)\n",
        "\n",
        "\n",
        "# Test data\n",
        "test_x = x_test\n",
        "test_y = y_test \n",
        "print(\"Test data shape:\", test_x.shape)\n",
        "\n",
        "# reshape data \n",
        "train_x = train_x.T\n",
        "test_x = test_x.T\n",
        "print(\"Training data shape:\", train_x.shape) \n",
        "print(\"Test data shape:\", test_x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (10000, 784)\n",
            "Test data shape: (10000, 784)\n",
            "Training data shape: (784, 10000)\n",
            "Test data shape: (784, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoXHKji6L3xo"
      },
      "source": [
        "### Network Architecture\n",
        "\n",
        "We will be using a two layer neural network in our experiment. The input layer has 784 nodes, the hidden layer will have 256 nodes and the output layer will have 10 nodes. First layer will have __sigmoid__ activation and second layer will have __softmax__ activation.\n",
        "\n",
        "The equations for feedforward operation will be as follows.\n",
        "\n",
        "$$\\mathbf{z}^{(1)}=W^{(1)} \\mathbf{x}+ \\mathbf{b}^{(1)}\\\\\\mathbf{y}^{(1)}=\\text{sigmoid}(\\mathbf{z}^{(1)})\\\\\\mathbf{z}^{(2)}=W^{(2)}  \\mathbf{y}^{(1)}+ \\mathbf{b}^{(2)} \\\\\\mathbf{p} = \\mathbf{y}^{(2)}=\\text{softmax}(\\mathbf{z}^{(2)})$$\n",
        "\n",
        "where $\\mathbf{x}\\in \\mathbb{R}^{784}$ is the input layer, $\\mathbf{y}^{(1)}\\in \\mathbb{R}^{256}$ is the hidden layer, $\\mathbf{y}^{(2)} \\in \\mathbb{R}$ is the output layer, $W^{(1)}\\in \\mathbb{R}^{256\\times 784}$ is the first layer weights, $W^{(2)}\\in \\mathbb{R}^{10\\times 256}$ is the second layer weights, $\\mathbf{b}^{(1)}\\in \\mathbb{R}^{256}$ is the first layer bias, $\\mathbf{b}^{(2)}\\in \\mathbb{R}^{10}$ is the second layer bias vector."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Fqsp1BvL3xp"
      },
      "source": [
        "### Network initialization [5 pts]\n",
        "\n",
        "We initialize the weights for $W^{(1)}$ and $W^{(2)}$ with random values drawn from normal distribution with zero mean and 0.01 standard deviation. We will initialize bias vectors $\\mathbf{b}^{(1)}$ and $\\mathbf{b^{(2)}}$ with zero values. \n",
        "\n",
        "We can fix the seed for random initialization for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu-3CQlRL3xp"
      },
      "source": [
        "def TwoLayerNetwork(layer_dims=[784,256,10]):\n",
        "    # TODO \n",
        "    # Your code goes here\n",
        "\n",
        "    # Fix the seed\n",
        "    np.random.seed(3)\n",
        "    \n",
        "    #Initialize the weights\n",
        "    w1 = np.random.normal(0, 0.01, size=(256,784))\n",
        "    w2 = np.random.normal(0, 0.01, size=(10,256))\n",
        "    b1 = np.zeros((256,1))\n",
        "    b2 = np.zeros((10,1))\n",
        "    params = [w1, w2, b1, b2]\n",
        "    \n",
        "    return params"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av7l9tOKUuAN"
      },
      "source": [
        "### Forward propagation \n",
        "Next, we will write the code for the forward pass for two layer network. Each layer consists of an affine function (fully-connected layer) followed by an activation function. You wil also return the intermediate results ($\\mathbf{x}, \\mathbf{z}^{(1)}, \\mathbf{y}^{(1)}, \\mathbf{z}^{(2)}$) in addition to final output ($\\mathbf{y}^{(2)}$). You will need the intermediate outputs for the backpropagation step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLSoTwFkUuAO"
      },
      "source": [
        "def forward(X, params):\n",
        "    \n",
        "    # TODO \n",
        "    # Write your codes here\n",
        "\n",
        "    # X -- 784 x N array \n",
        "    # params -- \n",
        "      # W1 -- 256 x 784 matrix\n",
        "      # b1 -- 256 x 1 vector\n",
        "      # W2 -- 10 x 256 matrix\n",
        "      # b2 -- 10 x 1 scalar \n",
        "    # probs -- 10 x N output \n",
        "    z1 = np.dot(params[0], X) + params[2]\n",
        "    y1 = sigmoid(z1)\n",
        "    z2 = np.dot(params[1], y1) + params[3]\n",
        "    probs = softmax(z2)\n",
        "    intermediate = [X, z1, y1, z2] \n",
        "\n",
        "    return probs, intermediate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3QjvXHIUuAO"
      },
      "source": [
        "### Backpropagration step [10 pts]\n",
        "\n",
        "Now we will implement the backpropagation step for the two layer neural network using softmax layer and loss function. \n",
        "\n",
        "\n",
        "You will need the gradient of the Loss w.r.t. $W^{(l)},\\mathbf{b}^{(l)}$ for $l = 1,2$ for all the training samples.  \n",
        "\n",
        "We saw that we can write the gradient of Loss with respect to $W^{(l)}, \\mathbf{b}^{(l)}$ for a single sample as\n",
        "\n",
        "$$\\nabla_{W^{(l)}} Loss_i = \\delta^{(l)} \\mathbf{y}^{(l-1)T},$$  \n",
        "$$\\nabla_{\\mathbf{b}^{(l)}} Loss_i = \\delta^{(l)},$$\n",
        "\n",
        "\n",
        "where \n",
        "$$\\delta^{(l)} = \\nabla_{\\mathbf{z}^{(l)}} Loss = \\nabla_{\\mathbf{y}^{(l)}} Loss \\odot \\varphi'(\\mathbf{z}^{(l)}).$$ \n",
        "\n",
        "We saw above that for an $i$th sample, $\\delta^{(2)} = \\nabla_{\\mathbf{z}^{(2)}} Loss_i = \\mathbf{p} - \\mathbf{1}_{y_i},$ where $\\mathbf{1}_{y_i}$ is a __one-hot vector__ that has length $K$ and is zero everywhere except 1 at index same as $y_i$ and $\\mathbf{p}$ is the outpu probability vector for the $i$th sample. \n",
        "\n",
        "\n",
        "**Once we have the gradients $\\nabla_{W^{(l)}} Loss_i, \\nabla_{\\mathbf{b}^{(l)}} Loss_i$ for all $i$. We can compute their average to compute the gradient of the total loss function as**\n",
        "\n",
        "$$\\nabla_{W^{(l)}} Loss = \\frac{1}{N} \\sum_i \\nabla_{W^{(l)}} Loss_i, $$\n",
        "$$ \\nabla_{\\mathbf{b}^{(l)}} Loss = \\frac{1}{N} \\sum_i  \\nabla_{\\mathbf{b}^{(l)}} Loss_i.$$\n",
        "\n",
        "**Please refer to the slides and lectures for more details.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0hPvx0SUuAP"
      },
      "source": [
        "def backward(Y_true, probs, intermediate, params):\n",
        "    \n",
        "    # Inputs: \n",
        "      # Y_true -- true labels\n",
        "      # probs -- 10 x N output of the last layer\n",
        "      # intermediate -- X, Z1, Y1, Z2 \n",
        "      # params -- W1, b1, W2, b2 \n",
        "    \n",
        "    # Outputs: \n",
        "      # grads -- [grad_W1, grad_b1, grad_W2, grad_b2]\n",
        "    \n",
        "    # TODO \n",
        "    # Write your codes here\n",
        "    x_transpose = np.transpose(intermediate[0])\n",
        "    Y_onehot = np.zeros(probs.shape)\n",
        "    for i in range(probs.shape[1]):\n",
        "      Y_onehot[int(Y_true[i]), i] = 1\n",
        "    \n",
        "    sigma2 = probs - Y_onehot\n",
        "\n",
        "    sigma1 = np.dot(params[1].T, sigma2)*sigmoid(intermediate[1])*(1-sigmoid(intermediate[1]))\n",
        "\n",
        "    grad_W1 = np.dot(sigma1, x_transpose)\n",
        "    grad_b1 = sigma1\n",
        "    y1_transpose = np.transpose(intermediate[2])\n",
        "\n",
        "    \n",
        "    # sigma2 = probs - Y_onehot\n",
        "    grad_W2 = np.dot(sigma2, y1_transpose)\n",
        "    grad_b2 = sigma2\n",
        "    grads = [grad_W1, grad_b1, grad_W2, grad_b2]    \n",
        "          \n",
        "    return grads\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DTxxcDTvVQD"
      },
      "source": [
        "### Train the model [5 pts]\n",
        "We will use the forward and backward functions defined above with the same optimizer defined in the previous question to train our multi-class classificaiton model. \n",
        "\n",
        "We will specify the number of nodes in the layers, number of epochs and learning rate and initialize the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmhkhUisUuAQ"
      },
      "source": [
        "layer_dims = [train_x.shape[0],256,10]\n",
        "epochs = 100\n",
        "lr = 0.00001\n",
        "\n",
        "params = TwoLayerNetwork(layer_dims)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DZAfG5QUuAQ"
      },
      "source": [
        "Then we train the network for the number of epochs specified above. In every epoch, we will do the following:\n",
        "1. Calculate the forward pass to get estimated labels.\n",
        "2. Use the estimated labels calculate loss. We will be recording loss for every epoch.\n",
        "3. Use backpropagation to calculate gradients.\n",
        "4. Use gradient descent to update the weights and biases.\n",
        "\n",
        "You should store the loss value after every epoch in an array ```loss_history```  and print the loss value after every few epochs (say 20). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1zSP6g8UuAQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd44158-b07d-44ed-ac08-4e482847e43f"
      },
      "source": [
        "# TODO \n",
        "# Write your codes here\n",
        "N = 10000\n",
        "loss_history = []\n",
        "for i in range(epochs):\n",
        "  probs, intermediate = forward(train_x, params) # Get the eastimated labels\n",
        "  loss = MultiClassCrossEntropyLoss(train_y, probs) # Calculate the loss between true label and eastimated labels\n",
        "  loss_history.append(loss)\n",
        "  grads = backward(train_y, probs, intermediate, params)\n",
        "  params = GD(params, grads, lr)\n",
        "  if i%20 == 0:\n",
        "    print(f\"Each {i} epochs's loss: \", loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Each 0 epochs's loss:  0.34285421129902127\n",
            "Each 20 epochs's loss:  0.24185762048038478\n",
            "Each 40 epochs's loss:  0.19401080246863622\n",
            "Each 60 epochs's loss:  0.15589841312161365\n",
            "Each 80 epochs's loss:  0.14101662098827059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAtKFEjTUuAQ"
      },
      "source": [
        "Now we will plot the recorded loss values vs epochs. We will observe the training loss decreasing with the epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw14IunrUuAQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "ec586480-1dd9-40b5-e367-ca05c5cbe1e0"
      },
      "source": [
        "plt.figure()\n",
        "plt.plot(loss_history)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf4fN1udUuAR"
      },
      "source": [
        "### Evaluation on test data [5 pts]\n",
        "\n",
        "Now we will be evaluating the accuracy we get from the trained model. We feed training data and test data to the forward model along with the trained parameters. \n",
        "\n",
        "Note that, we need to convert the (probability) output of the forward pass into labels before evaluating accuracy. We can assign label based on the maximum probability. \n",
        "\n",
        "We assign estimated labels $$\\hat{y}_i = \\arg \\max_c  \\mathbf{p}_c $$ for every probility vector. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAhOtQigUuAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "654c3ae2-62a3-480d-9b89-05f31f83cf6e"
      },
      "source": [
        "# TODO  \n",
        "probs_east_lab = np.argmax(probs, axis=0)\n",
        "\n",
        "print(\"Training accuracy:\",np.mean(probs_east_lab==train_y))\n",
        "\n",
        "probs_test, intermediate = forward(test_x, params)\n",
        "\n",
        "probs_test_east_lab = np.argmax(probs, axis=0)\n",
        "test_y_sorted = sorted(test_y)\n",
        "print(\"Test accuracy:\",np.mean(probs_test_east_lab == test_y_sorted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.9699\n",
            "Test accuracy: 0.9086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLjwg5wjMcyB"
      },
      "source": [
        "### Visualize some of the correct/miscalassified images [optional]\n",
        "\n",
        "Now we will look at some images from training and test sets that were misclassified. \n",
        "\n",
        "Training set. \n",
        "Pick example from each class that are correcly and incorreclty classified. \n",
        "True/False Positive/Negatives\n",
        "\n",
        "Test set. \n",
        "Pick examples from each class that are correcly and incorreclty classified. \n",
        "True/False Positive/Negatives\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-NtpDz-Mkub",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "outputId": "25fceae8-7f1d-4e4e-f922-5afe73dd6242"
      },
      "source": [
        "# TODO \n",
        "import random\n",
        "# TODO \n",
        "# Your code goes here ...\n",
        "# Training set\n",
        "print(\"Training set examples for true/false positive/negative\")\n",
        "P1, caches = forward(train_x, params)\n",
        "\n",
        "# your code goes here...\n",
        "P1 = np.argmax(P1, axis=0)\n",
        "\n",
        "corr_list = []\n",
        "incorr_list = []\n",
        "count = 0\n",
        "for i in P1==train_y:\n",
        "  count += 1\n",
        "  if i == 1:\n",
        "    corr_list.append(count)\n",
        "  else:\n",
        "    incorr_list.append(count)\n",
        "\n",
        "n_img=5\n",
        "\n",
        "train_x_fig = train_x.T\n",
        "train_x_fig = train_x_fig.reshape(10000,28,28)\n",
        "\n",
        "# correct images\n",
        "print(\"Correct images\")\n",
        "plt.figure(figsize=(n_img*2,2))\n",
        "plt.gray()\n",
        "for i in range(n_img):\n",
        "  x = random.randrange(i,len(corr_list))\n",
        "  plt.subplot(1,n_img,i+1)\n",
        "  plt.imshow(train_x_fig[corr_list[x]])\n",
        "plt.show()\n",
        "\n",
        "# incorrect images\n",
        "print(\"Incorrect images\")\n",
        "plt.figure(figsize=(n_img*2,2))\n",
        "plt.gray()\n",
        "for i in range(n_img):\n",
        "  x = random.randrange(i,len(incorr_list))\n",
        "  plt.subplot(1,n_img,i+1)\n",
        "  plt.imshow(train_x_fig[incorr_list[x]])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set examples for true/false positive/negative\n",
            "Correct images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x144 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Incorrect images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x144 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU1ZfPTjv-jm"
      },
      "source": [
        "### Note about implementation\n",
        "\n",
        "This is a note on two problems I have seen in the past and how they can be easily fixed. \n",
        "\n",
        "1. Summation along different axes ? \n",
        "\n",
        "2. Summation of gradients over samples ? \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**1. Summation to create probability vectors in the Softmax function**\n",
        "\n",
        "Suppose X is a d x N array, in our case, it is 784 x 10000. \n",
        "\n",
        "`Z2 = W2 Y1 + b2  will be 10 x 10000 array `\n",
        "\n",
        "\n",
        "\n",
        "`softmax(Z2)` will be a `10 x 10000` array in which we want to apply a softmax function on every column of `Z2` by first computing exponential and then normalizing the column to sum to 1, which is needed for it to be a probability vector. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "We can do that as \n",
        "```\n",
        "probs = np.exp(Z2) \n",
        "\n",
        "# now you want to sum up each column and divide the column by the sum so that each column is a valid probability vector\n",
        "\n",
        "probs /= np.sum(probs,axis=0,keepdims=True) # this makes sum of each column to 1\n",
        "```\n",
        "\n",
        "The **WRONG** thing to do is\n",
        "```\n",
        "probs /= np.sum(probs) \n",
        "# This is WRONG. np.sum() computes sum of the entire array. \n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "**2. Computing gradient for the entire loss function**\n",
        "\n",
        "(this involves summation of N rank-one matrices in our notation.)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Suppose you have computed delta1, delta2 properly\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Let's assume you computed\n",
        "```\n",
        "# delta2 is a 10 x 10000 array\n",
        "# Y1 is a 256 x 10000 array\n",
        "# N is 10000\n",
        "# grad_W2 should be a 10 x 256 array\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "We can expand the formula for the gradient of the overall loss. \n",
        "\n",
        "$$\\nabla_{W^{(2)}} Loss = \\frac{1}{N}\\sum_i \\nabla_{W^{(2)}} Loss_i, $$ \n",
        "\n",
        "where \n",
        "\n",
        "$$\\nabla_{W^{(2)}} Loss_i = \\delta^{(2)} y^{(1)T}$$ is the gradient of the loss for $i$th training sample, where $\\delta^{(2)}$ is a column of length 10 and $y^{(1)T}$ is a row of length 256, corresponding to $i$th training sample. Matrix product of column and row gives a a rank-1 matrix of size 10 x 256. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "To compute the gradient of loss over all the training samples, we need to average the rank-1 matrices for all N training samples.\n",
        "\n",
        "\n",
        "We can write the code for that as \n",
        "\n",
        "```\n",
        "# Sum gradient of loss for each sample\n",
        "for i in range(N):\n",
        "\tgrad_W2 += (1/N)*delta2[:,i,None].dot(Y1[:,i,None].T)\n",
        "\n",
        "# OR we can compute grad_W2 without for loop as \n",
        "grad_W2 = 1/N*np.dot(delta2,Y1.T)\n",
        "```\n",
        "\n",
        "To see why this is true, you can convince yourself that matrix product of an `M x N` matrix with an `N x K` matrix can be written as a summation of N `M x K` rank-one matricess. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Suppose \n",
        "\n",
        "$A = [\\mathbf{a}_1 ~ \\cdots ~ \\mathbf{a}_N] \\text{ and } B  = \\begin{bmatrix} \\mathbf{b}_1^T \\\\ \\vdots \\\\ \\mathbf{b}_N^T \\end{bmatrix},$\n",
        "\n",
        "where $\\mathbf{a}_i, \\mathbf{b}_i$ are columns of length $M, K$, respectively.  \n",
        "\n",
        " \n",
        "\n",
        "We can write $AB$ as \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "$$AB = \\sum_{i = 1}^N \\mathbf{a}_i \\mathbf{b}_i^T.$$ \n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Submission instructions\n",
        "1. Download this Colab to ipynb, and convert it to PDF. Follow similar steps as [here](https://stackoverflow.com/questions/53460051/convert-ipynb-notebook-to-html-in-google-colab) but convert to PDF.\n",
        " - Download your .ipynb file. You can do it using only Google Colab. `File` -> `Download` -> `Download .ipynb`\n",
        " - Reupload it so Colab can see it. Click on the `Files` icon on the far left to expand the side bar. You can directly drag the downloaded .ipynb file to the area. Or click `Upload to session storage` icon and then select & upload your .ipynb file.\n",
        " - Conversion using %%shell. \n",
        " ```\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install texlive-xetex texlive-fonts-recommended texlive-generic-recommended\n",
        "!jupyter nbconvert --log-level CRITICAL --to pdf name_of_hw.ipynb\n",
        "  ```\n",
        " - Your PDF file is ready. Click 3 dots and `Download`.\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "2. Upload the PDF to Gradescope, select the correct pdf pages for each question. **Important!**\n",
        "\n",
        "3. Upload the ipynb file to Gradescope\n",
        "\n",
        "\n",
        "Notice:\n",
        "In case of errors in conversion, please check your LaTeX and debug. In Markdown, when you write in LaTeX math mode, do not leave any leading and trailing whitespaces inside the dollar signs ($). For example, write `(dollarSign)\\mathbf(dollarSign)(dollarSign)` instead of `(dollarSign)(space)\\mathbf{w}(dollarSign)`. Otherwise, nbconvert will throw an error and the generated pdf will be incomplete. [This is a bug of nbconvert.](https://tex.stackexchange.com/questions/367176/jupyter-notebook-latex-conversion-fails-escaped-and-other-symbols)\n"
      ],
      "metadata": {
        "id": "WecX82dMRrVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install texlive-xetex texlive-fonts-recommended texlive-generic-recommended"
      ],
      "metadata": {
        "id": "ub1l1I4ZRqSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --log-level CRITICAL --to pdf fall2022_hw3.ipynb # make sure the ipynb name is correct"
      ],
      "metadata": {
        "id": "M2XuF-qZ_-fk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kMCJzii39h4d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}